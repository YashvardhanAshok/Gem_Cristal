import json
import os

file_paths = [
    "db/json/2n3lfJrK MINISTRY OF DEFENCE.json",
    "db/json/9ZRLmmxP MINISTRY OF COMMUNICATIONS.json",
    "db/json/DWaDzXu0 MINISTRY OF POWER.json",
    "db/json/gem.json",
    "db/json/hVnRg1YR MINISTRY OF HOME AFFAIRS.json",
    "db/json/main.json",
    "db/json/QCpNKez1 MINISTRY OF HOME AFFAIRS.json",
    "db/json/SMPqv70m MINISTRY OF DEFENCE.json",
    "db/json/SQdAXrbv MINISTRY OF CIVIL AVIATION.json",
    "db/json/WBdiDTzq MINISTRY OF HEALTH AND FAMILY WELFARE.json",
    "db/json/WWIPV7W4 MINISTRY OF DEFENCE.json",
]

combined_data = []
seen = set()

def normalize_data(data):
    # Try to get list of items from different structures
    if isinstance(data, list):
        return data
    elif isinstance(data, dict):
        for key in data:
            if isinstance(data[key], list):
                return data[key]
        return [data]  # If it's just a single object
    return []

for path in file_paths:
    if not os.path.exists(path):
        print(f"❌ File not found: {path}")
        continue

    if os.path.getsize(path) == 0:
        print(f"⚠️  Skipping empty file: {path}")
        continue

    try:
        with open(path, 'r', encoding='utf-8') as f:
            content = json.load(f)
            items = normalize_data(content)
            for item in items:
                # Remove full duplicates
                identifier = json.dumps(item, sort_keys=True)
                if identifier not in seen:
                    combined_data.append(item)
                    seen.add(identifier)
    except Exception as e:
        print(f"❌ Error processing {path}: {e}")

# Save to final file
output_path = "db/json/combined.json"
with open(output_path, 'w', encoding='utf-8') as out_file:
    json.dump(combined_data, out_file, indent=2, ensure_ascii=False)

print(f"\n✅ Combined {len(combined_data)} unique items into '{output_path}'")
